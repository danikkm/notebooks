{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T14:27:19.114437Z",
     "start_time": "2021-03-21T14:27:18.275702Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as tmodels\n",
    "\n",
    "from torchsummary import summary\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, f1_score, accuracy_score, plot_confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "import pickle\n",
    "\n",
    "from extra.utils import *\n",
    "from models.loader import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preconfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T14:27:19.905575Z",
     "start_time": "2021-03-21T14:27:19.861131Z"
    }
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T13:53:25.757912Z",
     "start_time": "2021-03-21T13:53:23.305068Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=False)\n",
    "model.model = model.model[:8]\n",
    "m = model.model[-1]  # last layer\n",
    "ch = m.conv.in_channels if hasattr(m, 'conv') else sum([x.in_channels for x in m.m])  # ch into module\n",
    "c = Classify(ch, nc)  # Classify()\n",
    "c.i, c.f, c.type = m.i, m.f, 'models.common.Classify'  # index, from, type\n",
    "model.model[-1] = c  # replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T14:38:57.875342Z",
     "start_time": "2021-03-21T14:38:57.782125Z"
    }
   },
   "outputs": [],
   "source": [
    "best_acc = 0\n",
    "start_epoch = 0\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 8 # 100-128 seems to be top performance\n",
    "\n",
    "# model, model_name, checkpoint_path = ModelLoader(batch_size=BATCH_SIZE,epochs=EPOCHS) \\\n",
    "#                                         .load_mobilenetv2(pretrained=False, num_classes=10)\n",
    "model, model_name, checkpoint_path = ModelLoader(batch_size=BATCH_SIZE,epochs=EPOCHS) \\\n",
    "                                        .load_mobilenetv3(mode='large',pretrained=False, num_classes=10)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "if device == 'cuda':\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T14:38:58.326280Z",
     "start_time": "2021-03-21T14:38:58.320523Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name, checkpoint_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T14:38:59.083376Z",
     "start_time": "2021-03-21T14:38:59.074515Z"
    }
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR preload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T14:27:51.412480Z",
     "start_time": "2021-03-21T14:27:50.181449Z"
    }
   },
   "outputs": [],
   "source": [
    "seed_everything(1337)\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T14:27:52.221920Z",
     "start_time": "2021-03-21T14:27:52.216083Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4) \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001) #0.0003, 0.001\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T14:27:52.643524Z",
     "start_time": "2021-03-21T14:27:52.641720Z"
    }
   },
   "outputs": [],
   "source": [
    "# summary(model, (3, 32, 32), batch_size=BATCH_SIZE, device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T18:40:20.552895Z",
     "start_time": "2021-03-20T18:40:20.495602Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# Load checkpoint.\n",
    "print('==> Resuming from checkpoint..')\n",
    "assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "best_acc = checkpoint['accuracy']\n",
    "start_epoch = checkpoint['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T14:27:53.424411Z",
     "start_time": "2021-03-21T14:27:53.418619Z"
    }
   },
   "outputs": [],
   "source": [
    "train_losses, train_accuracies = [], []\n",
    "test_losses, test_accuracies = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T14:27:53.901740Z",
     "start_time": "2021-03-21T14:27:53.892489Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_nn(epoch):\n",
    "    model.train()\n",
    "    with tqdm(trainloader, unit='batch') as tepoch:\n",
    "        for data, target in tepoch:\n",
    "            tepoch.set_description(f'Train epoch {epoch}')\n",
    "\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with torch.cuda.amp.autocast():\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "\n",
    "            _, predictions = output.max(1)\n",
    "            correct = predictions.eq(target).sum().item()\n",
    "            accuracy = (predictions == target).float().mean()\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_losses.append(loss.item())\n",
    "            train_accuracies.append(accuracy.item())\n",
    "            \n",
    "            tepoch.set_postfix(loss=loss.item(), accuracy=100. * accuracy.item(), last_lr=scheduler.get_last_lr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T14:27:54.446998Z",
     "start_time": "2021-03-21T14:27:54.434020Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_nn(epoch):\n",
    "    global best_acc\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        with tqdm(testloader, unit='batch') as tepoch:\n",
    "            for data, target in tepoch:\n",
    "                tepoch.set_description(f'Test epoch {epoch}')\n",
    "                \n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output = model(data)\n",
    "                _, predictions = output.max(1)\n",
    "                loss = criterion(output, target)\n",
    "                correct = predictions.eq(target).sum().item()\n",
    "                accuracy = (predictions == target).float().mean()\n",
    "                \n",
    "                if accuracy > best_acc:\n",
    "                    state = {\n",
    "                        'model': model.state_dict(),\n",
    "                        'accuracy': accuracy,\n",
    "                        'epoch': epoch,\n",
    "                    }\n",
    "                    if not os.path.isdir('checkpoint'):\n",
    "                        os.mkdir('checkpoint')\n",
    "                    torch.save(state, checkpoint_path)\n",
    "                    best_acc = accuracy\n",
    "                \n",
    "                test_losses.append(loss.item())\n",
    "                test_accuracies.append(accuracy.item())\n",
    "                \n",
    "                tepoch.set_postfix(loss=loss.item(), accuracy=100. * accuracy.item(), last_lr=scheduler.get_last_lr())     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T14:31:41.794093Z",
     "start_time": "2021-03-21T14:27:57.088408Z"
    }
   },
   "outputs": [],
   "source": [
    "for epoch in trange(start_epoch, start_epoch+EPOCHS):\n",
    "    train_nn(epoch)\n",
    "    test_nn(epoch)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save losses and accuracies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T14:36:51.859349Z",
     "start_time": "2021-03-21T14:36:51.849470Z"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(train_losses, open(f'./storage/{model_name}_train_losses_bs{BATCH_SIZE}_ep{EPOCHS}.pickle', 'wb'))\n",
    "pickle.dump(train_accuracies, open(f'./storage/{model_name}_train_accuracies_bs{BATCH_SIZE}_ep{EPOCHS}.pickle', 'wb'))\n",
    "pickle.dump(test_losses, open(f'./storage/{model_name}_test_losses_bs{BATCH_SIZE}_ep{EPOCHS}.pickle', 'wb'))\n",
    "pickle.dump(test_accuracies, open(f'./storage/{model_name}_test_accuracies_bs{BATCH_SIZE}_ep{EPOCHS}.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load losses and accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "train_losses = unpickle(f'./storage/{model_name}_train_losses_bs{BATCH_SIZE}_ep{EPOCHS}.pickle')\n",
    "train_accuracies = unpickle(f'./storage/{model_name}_train_accuracies_bs{BATCH_SIZE}_ep{EPOCHS}.pickle')\n",
    "test_losses = unpickle(f'./storage/{model_name}_test_losses_bs{BATCH_SIZE}_ep{EPOCHS}.pickle')\n",
    "test_accuracies = unpickle(f'./storage/{model_name}_test_accuracies_bs{BATCH_SIZE}_ep{EPOCHS}.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T14:36:53.793017Z",
     "start_time": "2021-03-21T14:36:53.759619Z"
    }
   },
   "outputs": [],
   "source": [
    "x = np.linspace(0, 15, num=15)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "plt.plot(train_losses, color='m', label='losses')\n",
    "plt.plot(train_accuracies, color='b', label='accuracies') \n",
    "plt.ylim(-0.1, 2.1)\n",
    "\n",
    "fig.suptitle('History of accuracy and loss on train data', fontsize=20)\n",
    "plt.xlabel('batch', fontsize=18)\n",
    "plt.ylabel('training loss', fontsize=16)\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T14:36:57.279171Z",
     "start_time": "2021-03-21T14:36:57.247684Z"
    }
   },
   "outputs": [],
   "source": [
    "x = np.linspace(0, 15, num=15)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "plt.plot(test_losses, color='m', label='losses')\n",
    "plt.plot(test_accuracies, color='b', label='accuracies') \n",
    "\n",
    "fig.suptitle('History of accuracy and loss on test data', fontsize=20)\n",
    "plt.xlabel('batch', fontsize=18)\n",
    "plt.ylabel('validation loss', fontsize=16)\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T14:37:05.368234Z",
     "start_time": "2021-03-21T14:37:05.325123Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, figsize=(12, 6), sharex=True)\n",
    "fig.suptitle('History of accuracy and loss on train data', fontsize=20)\n",
    "ax1.plot(train_accuracies)\n",
    "ax1.set_ylabel(\"training accuracy\")\n",
    "ax2.plot(train_losses)\n",
    "ax2.set_ylabel(\"training loss\")\n",
    "ax2.set_xlabel(\"batches\");\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T14:37:08.935059Z",
     "start_time": "2021-03-21T14:37:08.891305Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, figsize=(12, 6), sharex=True)\n",
    "fig.suptitle('History of accuracy and loss on test data', fontsize=20)\n",
    "ax1.plot(test_accuracies)\n",
    "ax1.set_ylabel(\"validation accuracy\")\n",
    "ax2.plot(test_losses)\n",
    "ax2.set_ylabel(\"validation loss\")\n",
    "ax2.set_xlabel(\"batches\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix, F1 score, accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T09:26:55.716612Z",
     "start_time": "2021-03-21T09:26:48.541119Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_label_predictions(model, device, test_loader):\n",
    "    model.eval()\n",
    "    actuals = []\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            prediction = output.argmax(dim=1, keepdim=True)\n",
    "            actuals.extend(target.view_as(prediction))\n",
    "            predictions.extend(prediction)\n",
    "    return [i.item() for i in actuals], [i.item() for i in predictions]\n",
    "\n",
    "actuals, predictions = test_label_predictions(model, device, testloader)\n",
    "print('Confusion matrix:')\n",
    "print(confusion_matrix(actuals, predictions, normalize='all'))\n",
    "print('F1 score: %f' % f1_score(actuals, predictions, average='micro'))\n",
    "print('Accuracy score: %f' % accuracy_score(actuals, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T22:33:17.133396Z",
     "start_time": "2021-03-20T22:33:17.120978Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_class_probabilities(model, device, test_loader, which_class):\n",
    "    model.eval()\n",
    "    actuals = []\n",
    "    probabilities = []\n",
    "    with torch.no_grad():\n",
    "        with tqdm(test_loader, unit='batch') as tepoch:\n",
    "            for data, target in tepoch:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output = model(data)            \n",
    "                prediction = output.argmax(dim=1, keepdim=True)\n",
    "                actuals.extend(target.view_as(prediction) == which_class)\n",
    "                probabilities.extend(torch.exp(output[:, which_class]))\n",
    "\n",
    "    return [i.item() for i in actuals], [i.item() for i in probabilities]\n",
    "\n",
    "which_class = classes.index(\"deer\")\n",
    "actuals, class_probabilities = test_class_probabilities(model, device, testloader, which_class)\n",
    "\n",
    "fpr, tpr, _ = roc_curve(actuals, class_probabilities)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "# plt.figure()\n",
    "lw = 2\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title(f'ROC for label={classes[which_class]}')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "# pickle.dump(fig, open(f'./figures/{name_of_model.lower()}_ROC_{epochs}_bs{batch_size}.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T14:37:18.898045Z",
     "start_time": "2021-03-21T14:37:18.892235Z"
    }
   },
   "outputs": [],
   "source": [
    "# loaded_model = MobileNetV2()\n",
    "# loaded_model = loaded_model.to(device)\n",
    "# if device == 'cuda':\n",
    "#     loaded_model = torch.nn.DataParallel(loaded_model)\n",
    "#     cudnn.benchmark = True\n",
    "# loaded_model.load_state_dict(torch.load('./state_dict_net_200.pt'))\n",
    "loaded_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T14:37:19.261724Z",
     "start_time": "2021-03-21T14:37:19.139682Z"
    }
   },
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing network, 1000 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T14:37:21.517604Z",
     "start_time": "2021-03-21T14:37:20.141273Z"
    }
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "loaded_model = loaded_model.cuda()\n",
    "with torch.no_grad():\n",
    "    with tqdm(testloader, unit=\"batch\") as tepoch:\n",
    "        for images, labels in tepoch:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = loaded_model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing network, accuracy of the each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T14:37:37.778271Z",
     "start_time": "2021-03-21T14:37:36.410033Z"
    }
   },
   "outputs": [],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "with torch.no_grad():\n",
    "    with tqdm(testloader, unit=\"batch\") as tepoch:\n",
    "        for images, labels in tepoch:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = loaded_model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            c = (predicted == labels).squeeze()\n",
    "            for i in range(4):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T20:26:14.582566Z",
     "start_time": "2021-03-19T20:26:14.579624Z"
    }
   },
   "outputs": [],
   "source": [
    "is_cuda(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T21:27:39.679164Z",
     "start_time": "2021-03-20T21:27:39.340993Z"
    }
   },
   "outputs": [],
   "source": [
    "X_val, Y_val = next(iter(testloader))\n",
    "Y_pred = model(X_val.to(device))\n",
    "Y_pred = torch.argmax(Y_pred, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T10:28:33.981196Z",
     "start_time": "2021-03-19T10:28:33.971679Z"
    }
   },
   "outputs": [],
   "source": [
    "Y_val[0].item()\n",
    "classes[Y_val[0].item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T10:28:44.384600Z",
     "start_time": "2021-03-19T10:28:44.175489Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 12))\n",
    "columns, rows = 4, 4\n",
    "for i in range(1, columns*rows+1):\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.imshow(X_val[i][0].squeeze(), cmap='gray')\n",
    "    \n",
    "    plt.title('real: {}, predicted: {}'.format(classes[Y_val[i].item()], classes[Y_pred[i].item()]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T20:51:59.970842Z",
     "start_time": "2021-03-11T20:51:59.798628Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "# lol = np.reshape(images[0].numpy(), (32, 32, 3))\n",
    "plt.imshow(np.transpose(images[0], (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T21:20:05.932710Z",
     "start_time": "2021-03-10T21:19:55.207223Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from six.moves import cPickle \n",
    "\n",
    "f = open('./data/cifar-10-batches-py/data_batch_1', 'rb')\n",
    "datadict = cPickle.load(f,encoding='latin1')\n",
    "f.close()\n",
    "X = datadict[\"data\"] \n",
    "Y = datadict['labels']\n",
    "X = X.reshape(10000, 3, 32, 32).transpose(0,2,3,1).astype(\"uint8\")\n",
    "Y = np.array(Y)\n",
    "\n",
    "#Visualizing CIFAR 10\n",
    "fig, axes1 = plt.subplots(5,5,figsize=(3,3))\n",
    "for j in range(5):\n",
    "    for k in range(5):\n",
    "        i = np.random.choice(range(len(X)))\n",
    "        axes1[j][k].set_axis_off()\n",
    "        axes1[j][k].imshow(X[i:i+1][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
