{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T20:25:38.197302Z",
     "start_time": "2021-03-11T20:25:37.849670Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torchsummary import summary\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from extra.utils import *\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preconfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T20:19:49.905531Z",
     "start_time": "2021-03-11T20:19:49.902712Z"
    }
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T20:19:50.136746Z",
     "start_time": "2021-03-11T20:19:49.973537Z"
    }
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    cudnn.benchmark = True\n",
    "    !nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR preload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T20:19:51.595461Z",
     "start_time": "2021-03-11T20:19:50.383293Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 64 # gtx960 - 64 in linux, 54 in windows\n",
    "epochs = 12\n",
    "seed_everything(1337)\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "#     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "#     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-06T12:28:26.912517Z",
     "start_time": "2021-02-06T12:28:26.908467Z"
    }
   },
   "source": [
    "## MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T20:19:51.599398Z",
     "start_time": "2021-03-11T20:19:51.596648Z"
    }
   },
   "outputs": [],
   "source": [
    "from models.mobilenetv2 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T20:19:52.768747Z",
     "start_time": "2021-03-11T20:19:51.600573Z"
    }
   },
   "outputs": [],
   "source": [
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "\n",
    "model = MobileNetV2()\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "if device == 'cuda':\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T20:19:52.774921Z",
     "start_time": "2021-03-11T20:19:52.769840Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(net.parameters(), lr=0.001,\n",
    "#                       momentum=0.9, weight_decay=5e-4)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T17:29:11.019669Z",
     "start_time": "2021-03-11T17:29:10.970398Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "summary(model, (3, 32, 32), batch_size=batch_size, device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T20:19:57.881058Z",
     "start_time": "2021-03-11T20:19:57.827252Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load checkpoint.\n",
    "print('==> Resuming from checkpoint..')\n",
    "assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n",
    "checkpoint = torch.load('./checkpoint/ckpt.pth')\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "best_acc = checkpoint['accuracy']\n",
    "start_epoch = checkpoint['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T18:09:09.561511Z",
     "start_time": "2021-03-11T18:09:09.556167Z"
    }
   },
   "outputs": [],
   "source": [
    "train_losses, train_accuracies = [], []\n",
    "test_losses, test_accuracies = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T18:09:09.569489Z",
     "start_time": "2021-03-11T18:09:09.562999Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_nn(epoch):\n",
    "    model.train()\n",
    "    with tqdm(trainloader, unit='batch') as tepoch:\n",
    "        for data, target in tepoch:\n",
    "            tepoch.set_description(f'Train epoch {epoch}')\n",
    "\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            _, predictions = output.max(1)\n",
    "            loss = criterion(output, target)\n",
    "            correct = predictions.eq(target).sum().item()\n",
    "            accuracy = (predictions == target).float().mean()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_losses.append(loss.item())\n",
    "            train_accuracies.append(accuracy.item())\n",
    "            \n",
    "            tepoch.set_postfix(loss=loss.item(), accuracy=100. * accuracy.item())\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T18:09:09.576650Z",
     "start_time": "2021-03-11T18:09:09.571060Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_nn(epoch):\n",
    "    global best_acc\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        with tqdm(testloader, unit='batch') as tepoch:\n",
    "            for data, target in tepoch:\n",
    "                tepoch.set_description(f'Test epoch {epoch}')\n",
    "                \n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output = model(data)\n",
    "                _, predictions = output.max(1)\n",
    "                loss = criterion(output, target)\n",
    "                correct = predictions.eq(target).sum().item()\n",
    "                accuracy = (predictions == target).float().mean()\n",
    "                \n",
    "                if accuracy > best_acc:\n",
    "                    state = {\n",
    "                        'model': model.state_dict(),\n",
    "                        'accuracy': accuracy,\n",
    "                        'epoch': epoch,\n",
    "                    }\n",
    "                    if not os.path.isdir('checkpoint'):\n",
    "                        os.mkdir('checkpoint')\n",
    "                    torch.save(state, './checkpoint/ckpt.pth')\n",
    "                    best_acc = accuracy\n",
    "                \n",
    "                test_losses.append(loss.item())\n",
    "                test_accuracies.append(accuracy.item())\n",
    "                \n",
    "                tepoch.set_postfix(loss=loss.item(), accuracy=100. * accuracy.item())     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T18:37:15.983004Z",
     "start_time": "2021-03-11T18:09:10.038099Z"
    }
   },
   "outputs": [],
   "source": [
    "for epoch in trange(start_epoch, start_epoch+epochs):\n",
    "    train_nn(epoch)\n",
    "    test_nn(epoch)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T18:37:16.157157Z",
     "start_time": "2021-03-11T18:37:15.984284Z"
    }
   },
   "outputs": [],
   "source": [
    "x = np.linspace(0, 15, num=15)\n",
    "\n",
    "fig = plt.figure(figsize=(8, 5))\n",
    "plt.plot(train_losses, color='m', label='losses')\n",
    "plt.plot(train_accuracies, color='b', label='accuracies') \n",
    "plt.ylim(-0.1, 2.1)\n",
    "\n",
    "fig.suptitle('History of accuracy and loss on train data', fontsize=20)\n",
    "plt.xlabel('batch', fontsize=18)\n",
    "plt.ylabel('training loss', fontsize=16)\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T18:37:16.294185Z",
     "start_time": "2021-03-11T18:37:16.158517Z"
    }
   },
   "outputs": [],
   "source": [
    "x = np.linspace(0, 15, num=15)\n",
    "\n",
    "fig = plt.figure(figsize=(8, 5))\n",
    "plt.plot(test_losses, color='m', label='losses')\n",
    "plt.plot(test_accuracies, color='b', label='accuracies') \n",
    "\n",
    "fig.suptitle('History of accuracy and loss on test data', fontsize=20)\n",
    "plt.xlabel('batch', fontsize=18)\n",
    "plt.ylabel('validation loss', fontsize=16)\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T18:37:16.500069Z",
     "start_time": "2021-03-11T18:37:16.295404Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, figsize=(12, 6), sharex=True)\n",
    "fig.suptitle('History of accuracy and loss on train data', fontsize=20)\n",
    "ax1.plot(train_accuracies)\n",
    "ax1.set_ylabel(\"training accuracy\")\n",
    "ax2.plot(train_losses)\n",
    "ax2.set_ylabel(\"training loss\")\n",
    "ax2.set_xlabel(\"batches\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T18:37:16.694061Z",
     "start_time": "2021-03-11T18:37:16.501104Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, figsize=(12, 6), sharex=True)\n",
    "fig.suptitle('History of accuracy and loss on test data', fontsize=20)\n",
    "ax1.plot(test_accuracies)\n",
    "ax1.set_ylabel(\"validation accuracy\")\n",
    "ax2.plot(test_losses)\n",
    "ax2.set_ylabel(\"validation loss\")\n",
    "ax2.set_xlabel(\"batches\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T19:47:43.989854Z",
     "start_time": "2021-02-08T19:47:43.957219Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), './state_dict_net_200.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T20:20:04.292303Z",
     "start_time": "2021-03-11T20:20:04.287144Z"
    }
   },
   "outputs": [],
   "source": [
    "# loaded_model = MobileNetV2()\n",
    "# loaded_model = loaded_model.to(device)\n",
    "# if device == 'cuda':\n",
    "#     loaded_model = torch.nn.DataParallel(loaded_model)\n",
    "#     cudnn.benchmark = True\n",
    "# loaded_model.load_state_dict(torch.load('./state_dict_net_200.pt'))\n",
    "loaded_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T18:40:39.751799Z",
     "start_time": "2021-03-11T18:40:39.695795Z"
    }
   },
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T18:40:40.316136Z",
     "start_time": "2021-03-11T18:40:40.202970Z"
    }
   },
   "outputs": [],
   "source": [
    "imshow(torchvision.utils.make_grid(images[0:4]))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing network, 4 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T18:40:42.641058Z",
     "start_time": "2021-03-11T18:40:42.196087Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loaded_model = loaded_model.cpu()\n",
    "loaded_outputs = loaded_model(images)\n",
    "_, loaded_predicted = torch.max(loaded_outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[loaded_predicted[j]]\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing network, 1000 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T18:40:53.447679Z",
     "start_time": "2021-03-11T18:40:46.153819Z"
    }
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "loaded_model = loaded_model.cuda()\n",
    "with torch.no_grad():\n",
    "    with tqdm(testloader, unit=\"batch\") as tepoch:\n",
    "        for images, labels in tepoch:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = loaded_model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing network, accuracy of the each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T18:41:19.088982Z",
     "start_time": "2021-03-11T18:41:11.770907Z"
    }
   },
   "outputs": [],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "with torch.no_grad():\n",
    "    with tqdm(testloader, unit=\"batch\") as tepoch:\n",
    "        for images, labels in tepoch:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = loaded_model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            c = (predicted == labels).squeeze()\n",
    "            for i in range(4):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T20:20:13.513682Z",
     "start_time": "2021-03-11T20:20:13.501688Z"
    }
   },
   "outputs": [],
   "source": [
    "is_cuda(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T20:51:19.045842Z",
     "start_time": "2021-03-11T20:51:11.739970Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_class_probabilities(model, device, test_loader, which_class):\n",
    "    model.eval()\n",
    "    actuals = []\n",
    "    probabilities = []\n",
    "    with torch.no_grad():\n",
    "        with tqdm(test_loader, unit='batch') as tepoch:\n",
    "            for data, target in tepoch:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output = model(data)            \n",
    "                prediction = output.argmax(dim=1, keepdim=True)\n",
    "                actuals.extend(target.view_as(prediction) == which_class)\n",
    "                probabilities.extend(torch.exp(output[:, which_class]))\n",
    "\n",
    "    return [i.item() for i in actuals], [i.item() for i in probabilities]\n",
    "\n",
    "which_class = 3\n",
    "actuals, class_probabilities = test_class_probabilities(model, device, testloader, which_class)\n",
    "\n",
    "fpr, tpr, _ = roc_curve(actuals, class_probabilities)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure()\n",
    "lw = 2\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC for label=cat(%d) class' % which_class)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T20:51:45.755646Z",
     "start_time": "2021-03-11T20:51:45.644586Z"
    }
   },
   "outputs": [],
   "source": [
    "X_val, Y_val = next(iter(testloader))\n",
    "Y_pred = model(X_val.to(device))\n",
    "Y_pred = torch.argmax(Y_pred, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T20:51:46.297843Z",
     "start_time": "2021-03-11T20:51:46.288186Z"
    }
   },
   "outputs": [],
   "source": [
    "Y_val[0].item()\n",
    "classes[Y_val[0].item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T20:51:48.748490Z",
     "start_time": "2021-03-11T20:51:47.457328Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 16))\n",
    "columns, rows = 4, 4\n",
    "for i in range(1, columns*rows+1):\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.imshow(X_val[i][0].squeeze(), cmap='gray')\n",
    "    \n",
    "    plt.title('real: {}, predicted: {}'.format(classes[Y_val[i].item()], classes[Y_pred[i].item()]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T20:51:59.970842Z",
     "start_time": "2021-03-11T20:51:59.798628Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "# lol = np.reshape(images[0].numpy(), (32, 32, 3))\n",
    "plt.imshow(np.transpose(images[0], (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T21:20:05.932710Z",
     "start_time": "2021-03-10T21:19:55.207223Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from six.moves import cPickle \n",
    "\n",
    "f = open('./data/cifar-10-batches-py/data_batch_1', 'rb')\n",
    "datadict = cPickle.load(f,encoding='latin1')\n",
    "f.close()\n",
    "X = datadict[\"data\"] \n",
    "Y = datadict['labels']\n",
    "X = X.reshape(10000, 3, 32, 32).transpose(0,2,3,1).astype(\"uint8\")\n",
    "Y = np.array(Y)\n",
    "\n",
    "#Visualizing CIFAR 10\n",
    "fig, axes1 = plt.subplots(5,5,figsize=(3,3))\n",
    "for j in range(5):\n",
    "    for k in range(5):\n",
    "        i = np.random.choice(range(len(X)))\n",
    "        axes1[j][k].set_axis_off()\n",
    "        axes1[j][k].imshow(X[i:i+1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
