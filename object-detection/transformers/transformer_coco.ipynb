{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ideal-sarah",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T20:41:07.668157Z",
     "start_time": "2021-04-17T20:41:07.662960Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "pip install pyyaml\n",
    "pip install easydict\n",
    "pip install -U pytorch_warmup\n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unauthorized-channels",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T20:41:08.711041Z",
     "start_time": "2021-04-17T20:41:07.669627Z"
    }
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import yaml\n",
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "from easydict import EasyDict as edict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.cuda import amp\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from models import DETR, SetCriterion\n",
    "from utils.dataset import collateFunction, COCODataset\n",
    "from utils.misc import MetricsLogger, saveArguments, logMetrics, cast2Float\n",
    "\n",
    "from utils.plots import plot_images, plot_labels, plot_results, plot_evolution\n",
    "from utils.general import increment_path\n",
    "\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correct-hungary",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T20:41:08.726309Z",
     "start_time": "2021-04-17T20:41:08.712459Z"
    }
   },
   "outputs": [],
   "source": [
    "CURRENT_PATH = os.path.join(os.getcwd())\n",
    "BASE_PATH = Path(CURRENT_PATH).parent\n",
    "CONFIG = os.path.join(CURRENT_PATH, 'config.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "committed-congo",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T20:41:08.745819Z",
     "start_time": "2021-04-17T20:41:08.730155Z"
    }
   },
   "outputs": [],
   "source": [
    "CURRENT_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greek-guatemala",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T20:41:08.761619Z",
     "start_time": "2021-04-17T20:41:08.747028Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_config():\n",
    "    with open(CONFIG, 'r') as stream:\n",
    "        try:\n",
    "            return yaml.safe_load(stream)\n",
    "        except yaml.YAMLError as exc:\n",
    "            raise ValueError(\"Failed to parse config requried\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specific-nightlife",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T20:41:08.779782Z",
     "start_time": "2021-04-17T20:41:08.762757Z"
    }
   },
   "outputs": [],
   "source": [
    "args = edict(parse_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "labeled-sending",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T20:41:08.805449Z",
     "start_time": "2021-04-17T20:41:08.780976Z"
    }
   },
   "outputs": [],
   "source": [
    "args.device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passing-taxation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T20:41:08.822211Z",
     "start_time": "2021-04-17T20:41:08.807393Z"
    }
   },
   "outputs": [],
   "source": [
    "saveArguments(args, args.taskName)\n",
    "torch.manual_seed(1337)\n",
    "device = torch.device(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afraid-spelling",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T20:41:08.842280Z",
     "start_time": "2021-04-17T20:41:08.823588Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dir = os.path.join(BASE_PATH, 'data/coco128/images/train2017')\n",
    "ann_dir = os.path.join(BASE_PATH, 'data/coco128/coco128.json')\n",
    "# train_dir = os.path.join(BASE_PATH, 'data/10k_coco/images')\n",
    "# ann_dir = os.path.join(BASE_PATH, 'data/10k_coco/train_80.json')\n",
    "\n",
    "dataset = COCODataset(train_dir,\n",
    "                      ann_dir,\n",
    "                      args.targetHeight,\n",
    "                      args.targetWidth,\n",
    "                      args.numClass)\n",
    "dataloader = DataLoader(dataset,\n",
    "                        batch_size=args.batchSize,\n",
    "                        shuffle=False,\n",
    "                        collate_fn=collateFunction,\n",
    "                        pin_memory=True,\n",
    "                        num_workers=args.numWorkers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "based-genetics",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T20:41:10.986870Z",
     "start_time": "2021-04-17T20:41:08.843505Z"
    }
   },
   "outputs": [],
   "source": [
    "model = DETR(args).to(device)\n",
    "criterion = SetCriterion(args).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prerequisite-sierra",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T20:41:11.005454Z",
     "start_time": "2021-04-17T20:41:10.987920Z"
    }
   },
   "outputs": [],
   "source": [
    "# if args.weightDir and os.path.exists(args.weightDir):\n",
    "#     print(f'loading pre-trained weights from {args.weightDir}')\n",
    "#     model.load_state_dict(torch.load(args.weightDir, map_location=device))\n",
    "\n",
    "# multi-GPU training\n",
    "if args.multi:\n",
    "    model = torch.nn.DataParallel(model)\n",
    "        \n",
    "# separate learning rate     \n",
    "paramDicts = [\n",
    "        {\"params\": [p for n, p in model.named_parameters() if \"backbone\" not in n and p.requires_grad]},\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters() if \"backbone\" in n and p.requires_grad],\n",
    "            \"lr\": args.lrBackbone,\n",
    "        },\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-scientist",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T20:41:11.022181Z",
     "start_time": "2021-04-17T20:41:11.006472Z"
    }
   },
   "outputs": [],
   "source": [
    "start_epoch = 0\n",
    "optimizer = AdamW(paramDicts, args.lr, weight_decay=args.weightDecay)\n",
    "lr_scheduler = StepLR(optimizer, args.lrDrop)\n",
    "prev_best_loss = np.inf\n",
    "batches = len(dataloader)\n",
    "logger = MetricsLogger()\n",
    "\n",
    "# import pytorch_warmup as warmup\n",
    "# warmup_scheduler = warmup.ExponentialWarmup(optimizer, warmup_period=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interim-measure",
   "metadata": {},
   "source": [
    "## Experemental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "announced-biotechnology",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T19:26:05.611373Z",
     "start_time": "2021-04-11T19:26:05.608789Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "save_dir = increment_path(Path(CURRENT_PATH) / args.project, exist_ok=True | False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ahead-desktop",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T19:26:11.347279Z",
     "start_time": "2021-04-11T19:26:11.344511Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressed-organization",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T19:30:27.755681Z",
     "start_time": "2021-04-11T19:30:27.750484Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "save_dir = Path(\"runs\")\n",
    "name = 'exp'\n",
    "wdir = save_dir / 'weights'\n",
    "wdir.mkdir(parents=True, exist_ok=True)  # make dir\n",
    "last = wdir / 'last.pt'\n",
    "best = wdir / 'best.pt'\n",
    "results_file = save_dir / 'results.txt'\n",
    "\n",
    "plots = True\n",
    "\n",
    "loggers = {'wandb': None}  # loggers dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divine-bubble",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T19:51:50.302359Z",
     "start_time": "2021-04-11T19:51:50.300244Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "from utils.plots import plot_images, plot_labels, plot_results, plot_evolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acknowledged-morgan",
   "metadata": {},
   "source": [
    "## Resume training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hawaiian-milwaukee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T20:32:47.913849Z",
     "start_time": "2021-04-17T20:32:47.769964Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "assert os.path.isdir('checkpoint')\n",
    "checkpoint = torch.load(f'{CHECKPOINT_PATH}/{args.datasetType}.pt')\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "prev_best_loss = checkpoint['loss']\n",
    "start_epoch = checkpoint['epoch']\n",
    "print(f'loss is: {prev_best_loss}, start from: {start_epoch}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "useful-stomach",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T20:41:11.046571Z",
     "start_time": "2021-04-17T20:41:11.025716Z"
    }
   },
   "outputs": [],
   "source": [
    "losses = []\n",
    "def train(epoch, prev_best_loss):\n",
    "    model.train()\n",
    "    criterion.train()\n",
    "    scaler = amp.GradScaler()\n",
    "    with tqdm(dataloader, unit='batch') as tepoch:\n",
    "        for (x, y) in tepoch:\n",
    "            tepoch.set_description(f'Train epoch {epoch}')\n",
    "            \n",
    "            x = x.to(device)\n",
    "            y = [{k: v.to(device) for k, v in t.items()} for t in y]\n",
    "\n",
    "            if args.amp:\n",
    "                with amp.autocast():\n",
    "                    out = model(x)\n",
    "                out = cast2Float(out)\n",
    "            else:\n",
    "                out = model(x)\n",
    "\n",
    "            metrics = criterion(out, y)\n",
    "            \n",
    "            loss = sum(v for k, v in metrics.items() if 'loss' in k)\n",
    "            losses.append(loss.cpu().item())\n",
    "\n",
    "            # MARK: - backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            if args.amp:\n",
    "                scaler.scale(loss).backward()\n",
    "                if args.clipMaxNorm > 0:\n",
    "                    scaler.unscale_(optimizer)\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), args.clipMaxNorm)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                loss.backward()\n",
    "                if args.clipMaxNorm > 0:\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), args.clipMaxNorm)\n",
    "                optimizer.step()\n",
    "            tepoch.set_postfix(loss=loss.cpu().item()) \n",
    "            \n",
    "        lr_scheduler.step()\n",
    "#         warmup_scheduler.dampen()\n",
    "        print(lr_scheduler.get_last_lr())\n",
    "        avg_loss = np.mean(losses)\n",
    "\n",
    "        if avg_loss < prev_best_loss:\n",
    "            print('[+] Loss improved from {:.8f} to {:.8f}, saving model...'.format(prev_best_loss,\n",
    "                                                                                    avg_loss))\n",
    "            \n",
    "            if not os.path.exists(args.outputDir):\n",
    "                os.mkdir(args.outputDir)\n",
    "\n",
    "            try:\n",
    "                state = {\n",
    "                'model': model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'lr_scheduler': lr_scheduler.state_dict(),\n",
    "                'loss': prev_best_loss,\n",
    "                'epoch': epoch\n",
    "                }\n",
    "            except AttributeError:\n",
    "                pass\n",
    "            torch.save(state, f'{args.outputDir}/{args.datasetType}.pt')\n",
    "            prev_best_loss = avg_loss\n",
    "        \n",
    "        # Plots    \n",
    "#         if epoch < 3:\n",
    "#             f = f'{args.project}/train_batch{epoch}.jpg'\n",
    "#             Thread(target=plot_images, args=(x, y, None, f), daemon=True).start()\n",
    "\n",
    "        with open(f'{args.outputDir}/losses.txt', 'a') as fd:\n",
    "            fd.write(f'\\n{prev_best_loss}')\n",
    "        return prev_best_loss\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "together-seminar",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T20:41:39.778184Z",
     "start_time": "2021-04-17T20:41:11.047602Z"
    }
   },
   "outputs": [],
   "source": [
    "for epoch in trange(start_epoch, start_epoch+args.epochs):\n",
    "    prev_best_loss = train(epoch, prev_best_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mounted-baseball",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "golden-dollar",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T11:20:50.726758Z",
     "start_time": "2021-03-27T11:20:50.712700Z"
    }
   },
   "outputs": [],
   "source": [
    "COLORS = [[0.000, 0.447, 0.741], [0.850, 0.325, 0.098], [0.929, 0.694, 0.125],\n",
    "          [0.494, 0.184, 0.556], [0.466, 0.674, 0.188], [0.301, 0.745, 0.933]]\n",
    "CLASSES = [\n",
    "    'N/A', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A',\n",
    "    'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse',\n",
    "    'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack',\n",
    "    'umbrella', 'N/A', 'N/A', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis',\n",
    "    'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove',\n",
    "    'skateboard', 'surfboard', 'tennis racket', 'bottle', 'N/A', 'wine glass',\n",
    "    'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich',\n",
    "    'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake',\n",
    "    'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table', 'N/A',\n",
    "    'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard',\n",
    "    'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A',\n",
    "    'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier',\n",
    "    'toothbrush'\n",
    "]\n",
    "transform2 = transforms.Compose([\n",
    "#     transforms.Resize(800),\n",
    "    transforms.Resize((38, 38)),\n",
    "    transforms.ToTensor(),\n",
    "#     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "def box_cxcywh_to_xyxy(x):\n",
    "    x_c, y_c, w, h = x.unbind(1)\n",
    "    b = [(x_c - 0.5 * w), (y_c - 0.5 * h),\n",
    "         (x_c + 0.5 * w), (y_c + 0.5 * h)]\n",
    "    return torch.stack(b, dim=1)\n",
    "\n",
    "def rescale_bboxes(out_bbox, size):\n",
    "    img_w, img_h = size\n",
    "    b = box_cxcywh_to_xyxy(out_bbox)\n",
    "    b = b * torch.tensor([img_w, img_h, img_w, img_h], dtype=torch.float32)\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tracked-marsh",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T11:06:40.900471Z",
     "start_time": "2021-03-27T11:06:40.893243Z"
    }
   },
   "outputs": [],
   "source": [
    "def detect(im, model, transform):\n",
    "    # mean-std normalize the input image (batch-size: 1)\n",
    "    img = transform(im).unsqueeze(0)\n",
    "\n",
    "    # demo model only support by default images with aspect ratio between 0.5 and 2\n",
    "    # if you want to use images with an aspect ratio outside this range\n",
    "    # rescale your image so that the maximum size is at most 1333 for best results\n",
    "    assert img.shape[-2] <= 1600 and img.shape[-1] <= 1600, 'demo model only supports images up to 1600 pixels on each side'\n",
    "\n",
    "    # propagate through the model\n",
    "#     img = img.to(device)\n",
    "    outputs = model(img)\n",
    "\n",
    "    # keep only predictions with 0.7+ confidence\n",
    "    probas = outputs['class'].softmax(-1)[0, :, :-1]\n",
    "    keep = probas.max(-1).values > 0.7\n",
    "\n",
    "    # convert boxes from [0; 1] to image scales\n",
    "    bboxes_scaled = rescale_bboxes(outputs['bbox'][0, keep], im.size)\n",
    "    return probas[keep], bboxes_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "special-conducting",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T11:01:10.436047Z",
     "start_time": "2021-03-27T11:01:09.841126Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "chk = torch.load('/home/daniel/Documents/coco/Modified-DETR/checkpoint/mango.pt', map_location=torch.device(\"cpu\"))\n",
    "\n",
    "model.load_state_dict(chk)\n",
    "cpu_model = model.to('cpu')\n",
    "# is_cuda(cpu_model)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assigned-exhaust",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-27T10:52:54.228Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n",
    "im = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "scores, boxes = detect(im, cpu_model, transform2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simple-swedish",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T11:06:58.630756Z",
     "start_time": "2021-03-27T11:06:56.758317Z"
    }
   },
   "outputs": [],
   "source": [
    "dataiter = iter(dataloader)\n",
    "images, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "every-summit",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T11:01:13.606656Z",
     "start_time": "2021-03-27T11:01:13.482987Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(np.transpose(images[1].numpy(), (1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raised-disposal",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T11:01:17.276089Z",
     "start_time": "2021-03-27T11:01:17.267154Z"
    }
   },
   "outputs": [],
   "source": [
    "CLASSES[labels[1]['labels'][-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlimited-excerpt",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T11:01:33.859895Z",
     "start_time": "2021-03-27T11:01:33.242518Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "loaded_outputs = cpu_model(images)\n",
    "probas = loaded_outputs['class'].softmax(-1)[0, :, :-1]\n",
    "probas.max(-1).values\n",
    "\n",
    "\n",
    "# tensor([0.1997, 0.1997, 0.1997, 0.1997, 0.1997, 0.1997, 0.1997, 0.1997, 0.1997,\n",
    "#         0.1997, 0.1997, 0.1997, 0.1997, 0.1997, 0.1997, 0.1997, 0.1997, 0.1997,\n",
    "#         0.1997, 0.1997, 0.1997, 0.1997, 0.1997, 0.1997, 0.1997, 0.1997, 0.1997,\n",
    "#         0.1997, 0.1997, 0.1997, 0.1997, 0.1997, 0.1997, 0.1997, 0.1997, 0.1997,\n",
    "#         0.1997, 0.1997, 0.1997, 0.1997, 0.1997, 0.1997, 0.1997, 0.1997, 0.1997,\n",
    "#         0.1997, 0.1997, 0.1997, 0.1997, 0.1997, 0.1997, 0.1997, 0.1997, 0.1997,\n",
    "#         0.1997, 0.1997, 0.1997, 0.1997, 0.1997, 0.1997, 0.1997, 0.1997, 0.1997,\n",
    "#         0.1997, 0.1997, 0.1997, 0.1997, 0.1997, 0.1997, 0.1997, 0.1997, 0.1997,\n",
    "#         0.1997, 0.1997, 0.1997, 0.1997, 0.1997, 0.1997, 0.1997, 0.1997, 0.1997,\n",
    "#         0.1997, 0.1997, 0.1997, 0.1997, 0.1997, 0.1997, 0.1997, 0.1997, 0.1997,\n",
    "#         0.1997, 0.1997, 0.1997, 0.1997, 0.1997, 0.1997, 0.1997, 0.1997, 0.1997,\n",
    "#         0.1997], grad_fn=<MaxBackward0>)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bored-payday",
   "metadata": {},
   "source": [
    "# Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recorded-elevation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T11:06:28.151972Z",
     "start_time": "2021-03-27T11:06:25.460012Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dir = os.path.join(BASE_PATH, 'data/coco_mini/trainset')\n",
    "ann_dir = os.path.join(BASE_PATH, 'data/coco_mini/instances_minitrain2017.json')\n",
    "\n",
    "dataset = COCODataset(train_dir,\n",
    "                      ann_dir,\n",
    "                      608, # 608\n",
    "                      608, # 608\n",
    "                      args.numClass)\n",
    "dataloader = DataLoader(dataset,\n",
    "                        batch_size=1,\n",
    "                        shuffle=False,\n",
    "                        collate_fn=collateFunction,\n",
    "                        pin_memory=True,\n",
    "                        num_workers=args.numWorkers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informed-johns",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T11:06:31.728641Z",
     "start_time": "2021-03-27T11:06:31.715404Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class DETRdemo(nn.Module):\n",
    "    \"\"\"\n",
    "    Demo DETR implementation.\n",
    "\n",
    "    Demo implementation of DETR in minimal number of lines, with the\n",
    "    following differences wrt DETR in the paper:\n",
    "    * learned positional encoding (instead of sine)\n",
    "    * positional encoding is passed at input (instead of attention)\n",
    "    * fc bbox predictor (instead of MLP)\n",
    "    The model achieves ~40 AP on COCO val5k and runs at ~28 FPS on Tesla V100.\n",
    "    Only batch size 1 supported.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes, hidden_dim=256, nheads=8,\n",
    "                 num_encoder_layers=6, num_decoder_layers=6):\n",
    "        super().__init__()\n",
    "\n",
    "        # create ResNet-50 backbone\n",
    "        self.backbone = resnet50()\n",
    "        del self.backbone.fc\n",
    "\n",
    "        # create conversion layer\n",
    "        self.conv = nn.Conv2d(2048, hidden_dim, 1)\n",
    "\n",
    "        # create a default PyTorch transformer\n",
    "        self.transformer = nn.Transformer(\n",
    "            hidden_dim, nheads, num_encoder_layers, num_decoder_layers)\n",
    "\n",
    "        # prediction heads, one extra class for predicting non-empty slots\n",
    "        # note that in baseline DETR linear_bbox layer is 3-layer MLP\n",
    "        self.linear_class = nn.Linear(hidden_dim, num_classes + 1)\n",
    "        self.linear_bbox = nn.Linear(hidden_dim, 4)\n",
    "\n",
    "        # output positional encodings (object queries)\n",
    "        self.query_pos = nn.Parameter(torch.rand(100, hidden_dim))\n",
    "\n",
    "        # spatial positional encodings\n",
    "        # note that in baseline DETR we use sine positional encodings\n",
    "        self.row_embed = nn.Parameter(torch.rand(50, hidden_dim // 2))\n",
    "        self.col_embed = nn.Parameter(torch.rand(50, hidden_dim // 2))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # propagate inputs through ResNet-50 up to avg-pool layer\n",
    "        x = self.backbone.conv1(inputs)\n",
    "        x = self.backbone.bn1(x)\n",
    "        x = self.backbone.relu(x)\n",
    "        x = self.backbone.maxpool(x)\n",
    "\n",
    "        x = self.backbone.layer1(x)\n",
    "        x = self.backbone.layer2(x)\n",
    "        x = self.backbone.layer3(x)\n",
    "        x = self.backbone.layer4(x)\n",
    "\n",
    "        # convert from 2048 to 256 feature planes for the transformer\n",
    "        h = self.conv(x)\n",
    "\n",
    "        # construct positional encodings\n",
    "        H, W = h.shape[-2:]\n",
    "        pos = torch.cat([\n",
    "            self.col_embed[:W].unsqueeze(0).repeat(H, 1, 1),\n",
    "            self.row_embed[:H].unsqueeze(1).repeat(1, W, 1),\n",
    "        ], dim=-1).flatten(0, 1).unsqueeze(1)\n",
    "\n",
    "        # propagate through the transformer\n",
    "        h = self.transformer(pos + 0.1 * h.flatten(2).permute(2, 0, 1),\n",
    "                             self.query_pos.unsqueeze(1)).transpose(0, 1)\n",
    "        \n",
    "        # finally project transformer outputs to class labels and bounding boxes\n",
    "        return {'pred_logits': self.linear_class(h), \n",
    "                'pred_boxes': self.linear_bbox(h).sigmoid()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norman-territory",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T11:06:32.836529Z",
     "start_time": "2021-03-27T11:06:32.254428Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50\n",
    "\n",
    "detr = DETRdemo(num_classes=91) \n",
    "state_dict = torch.hub.load_state_dict_from_url(\n",
    "    url='https://dl.fbaipublicfiles.com/detr/detr_demo-da2a99e9.pth',\n",
    "    map_location='cpu', check_hash=True)\n",
    "detr.load_state_dict(state_dict)\n",
    "detr.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "otherwise-entity",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T11:22:29.992437Z",
     "start_time": "2021-03-27T11:22:29.982631Z"
    }
   },
   "outputs": [],
   "source": [
    "def box_cxcywh_to_xyxy2(x):\n",
    "    x_c, y_c, w, h = x.unbind(1)\n",
    "    b = [(x_c - 0.5 * w), (y_c - 0.5 * h),\n",
    "         (x_c + 0.5 * w), (y_c + 0.5 * h)]\n",
    "    return torch.stack(b, dim=1)\n",
    "\n",
    "def rescale_bboxes2(out_bbox, size):\n",
    "    _, _, img_w, img_h = size\n",
    "    b = box_cxcywh_to_xyxy2(out_bbox)\n",
    "    b = b * torch.tensor([img_w, img_h, img_w, img_h], dtype=torch.float32)\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "failing-serum",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T11:22:22.725087Z",
     "start_time": "2021-03-27T11:22:22.715291Z"
    }
   },
   "outputs": [],
   "source": [
    "def detectDemo(im, model, transform):\n",
    "    # mean-std normalize the input image (batch-size: 1)\n",
    "#     img = transform(im)\n",
    "    img = im\n",
    "\n",
    "    # demo model only support by default images with aspect ratio between 0.5 and 2\n",
    "    # if you want to use images with an aspect ratio outside this range\n",
    "    # rescale your image so that the maximum size is at most 1333 for best results\n",
    "    assert img.shape[-2] <= 1600 and img.shape[-1] <= 1600, 'demo model only supports images up to 1600 pixels on each side'\n",
    "\n",
    "    # propagate through the model\n",
    "#     img = img.to(device)\n",
    "    outputs = model(img)\n",
    "\n",
    "    # keep only predictions with 0.7+ confidence\n",
    "    probas = outputs['pred_logits'].softmax(-1)[0, :, :-1]\n",
    "    keep = probas.max(-1).values > 0.7\n",
    "\n",
    "    # convert boxes from [0; 1] to image scales\n",
    "    bboxes_scaled = rescale_bboxes2(outputs['pred_boxes'][0, keep], im.size())\n",
    "    return probas[keep], bboxes_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "working-hungarian",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T11:43:40.043633Z",
     "start_time": "2021-03-27T11:43:40.024945Z"
    }
   },
   "outputs": [],
   "source": [
    "transform2(example[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pretty-average",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T11:34:15.668034Z",
     "start_time": "2021-03-27T11:34:14.361546Z"
    }
   },
   "outputs": [],
   "source": [
    "example = iter(dataloader).next()[0]\n",
    "scores, boxes = detectDemo(example, detr, transform2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "progressive-involvement",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T11:39:27.871055Z",
     "start_time": "2021-03-27T11:39:27.864887Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_image =  np.transpose(example[0].numpy(), (1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "remarkable-budget",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T12:25:15.643533Z",
     "start_time": "2021-03-27T12:25:15.379991Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_results(pil_img, prob, boxes):\n",
    "    plt.figure(figsize=(16,10))\n",
    "    plt.imshow(pil_img)\n",
    "    ax = plt.gca()\n",
    "    for p, (xmin, ymin, xmax, ymax), c in zip(prob, boxes.tolist(), COLORS * 100):\n",
    "        ax.add_patch(plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,\n",
    "                                   fill=False, color=c, linewidth=3))\n",
    "        cl = p.argmax()\n",
    "        text = f'{CLASSES[cl]}: {p[cl]:0.2f}'\n",
    "        ax.text(xmin, ymin, text, fontsize=15,\n",
    "                bbox=dict(facecolor='yellow', alpha=0.5))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "plot_results(example[0][0], scores, boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prospective-extent",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
