{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ideal-sarah",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T20:54:25.123241Z",
     "start_time": "2021-03-23T20:54:25.121255Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "pip install pyyaml\n",
    "pip install easydict\n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unauthorized-channels",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-25T17:34:38.965627Z",
     "start_time": "2021-03-25T17:34:38.962208Z"
    }
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "from easydict import EasyDict as edict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.cuda import amp\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "from models import DETR, SetCriterion\n",
    "from utils.dataset import collateFunction, COCODataset\n",
    "from utils.misc import MetricsLogger, saveArguments, logMetrics, cast2Float\n",
    "\n",
    "from tqdm.notebook import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correct-hungary",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-25T17:34:40.035471Z",
     "start_time": "2021-03-25T17:34:40.031522Z"
    }
   },
   "outputs": [],
   "source": [
    "CURRENT_PATH = os.path.join(os.getcwd())\n",
    "BASE_PATH = Path(CURRENT_PATH).parent\n",
    "CONFIG = os.path.join(CURRENT_PATH, 'config.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caring-retirement",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-25T17:34:40.343769Z",
     "start_time": "2021-03-25T17:34:40.337243Z"
    }
   },
   "outputs": [],
   "source": [
    "BASE_PATH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greek-guatemala",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-25T17:35:26.901309Z",
     "start_time": "2021-03-25T17:35:26.898820Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_config():\n",
    "    with open(CONFIG, 'r') as stream:\n",
    "        try:\n",
    "            return yaml.safe_load(stream)\n",
    "        except yaml.YAMLError as exc:\n",
    "            raise ValueError(\"Failed to parse config requried\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specific-nightlife",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-25T17:35:27.158910Z",
     "start_time": "2021-03-25T17:35:27.148192Z"
    }
   },
   "outputs": [],
   "source": [
    "args = edict(parse_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "labeled-sending",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-25T17:35:27.581791Z",
     "start_time": "2021-03-25T17:35:27.551808Z"
    }
   },
   "outputs": [],
   "source": [
    "args.device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passing-taxation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-25T17:35:27.992721Z",
     "start_time": "2021-03-25T17:35:27.989923Z"
    }
   },
   "outputs": [],
   "source": [
    "saveArguments(args, args.taskName)\n",
    "torch.manual_seed(1337)\n",
    "device = torch.device(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afraid-spelling",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-25T17:35:31.514958Z",
     "start_time": "2021-03-25T17:35:28.655967Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dir = os.path.join(BASE_PATH, 'data/coco_mini/trainset')\n",
    "ann_dir = os.path.join(BASE_PATH, 'data/coco_mini/instances_minitrain2017.json')\n",
    "\n",
    "dataset = COCODataset(train_dir,\n",
    "                      ann_dir,\n",
    "                      args.targetHeight,\n",
    "                      args.targetWidth,\n",
    "                      args.numClass)\n",
    "dataloader = DataLoader(dataset,\n",
    "                        batch_size=args.batchSize,\n",
    "                        shuffle=True,\n",
    "                        collate_fn=collateFunction,\n",
    "                        pin_memory=True,\n",
    "                        num_workers=args.numWorkers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "based-genetics",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T20:54:30.567640Z",
     "start_time": "2021-03-23T20:54:28.545748Z"
    }
   },
   "outputs": [],
   "source": [
    "model = DETR(args).to(device)\n",
    "criterion = SetCriterion(args).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prerequisite-sierra",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T20:54:30.574254Z",
     "start_time": "2021-03-23T20:54:30.568813Z"
    }
   },
   "outputs": [],
   "source": [
    "if args.weightDir and os.path.exists(args.weightDir):\n",
    "    print(f'loading pre-trained weights from {args.weightDir}')\n",
    "    model.load_state_dict(torch.load(args.weightDir, map_location=device))\n",
    "\n",
    "# multi-GPU training\n",
    "if args.multi:\n",
    "    model = torch.nn.DataParallel(model)\n",
    "        \n",
    "# separate learning rate     \n",
    "paramDicts = [\n",
    "        {\"params\": [p for n, p in model.named_parameters() if \"backbone\" not in n and p.requires_grad]},\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters() if \"backbone\" in n and p.requires_grad],\n",
    "            \"lr\": args.lrBackbone,\n",
    "        },\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-scientist",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T20:54:30.581932Z",
     "start_time": "2021-03-23T20:54:30.575440Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = AdamW(paramDicts, args.lr, weight_decay=args.weightDecay)\n",
    "lrScheduler = StepLR(optimizer, args.lrDrop)\n",
    "prevBestLoss = np.inf\n",
    "batches = len(dataloader)\n",
    "logger = MetricsLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "useful-stomach",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T20:54:30.598523Z",
     "start_time": "2021-03-23T20:54:30.589571Z"
    }
   },
   "outputs": [],
   "source": [
    "losses = []\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    criterion.train()\n",
    "    scaler = amp.GradScaler()\n",
    "    with tqdm(dataloader, unit='batch') as tepoch:\n",
    "        for (x, y) in tepoch:\n",
    "            tepoch.set_description(f'Train epoch {epoch}')\n",
    "            x = x.to(device)\n",
    "            y = [{k: v.to(device) for k, v in t.items()} for t in y]\n",
    "\n",
    "            if args.amp:\n",
    "                with amp.autocast():\n",
    "                    out = model(x)\n",
    "                out = cast2Float(out)\n",
    "            else:\n",
    "                out = model(x)\n",
    "\n",
    "            metrics = criterion(out, y)\n",
    "        \n",
    "            loss = sum(v for k, v in metrics.items() if 'loss' in k)\n",
    "            losses.append(loss.cpu().item())\n",
    "\n",
    "            # MARK: - backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            if args.amp:\n",
    "                scaler.scale(loss).backward()\n",
    "                if args.clipMaxNorm > 0:\n",
    "                    scaler.unscale_(optimizer)\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), args.clipMaxNorm)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                loss.backward()\n",
    "                if args.clipMaxNorm > 0:\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), args.clipMaxNorm)\n",
    "                optimizer.step()\n",
    "            tepoch.set_postfix(loss=loss.cpu().item()) \n",
    "            \n",
    "        lrScheduler.step()\n",
    "\n",
    "        avgLoss = np.mean(losses)\n",
    "\n",
    "        if avgLoss < prevBestLoss:\n",
    "            print('[+] Loss improved from {:.8f} to {:.8f}, saving model...'.format(prevBestLoss, avgLoss))\n",
    "            if not os.path.exists(args.outputDir):\n",
    "                os.mkdir(args.outputDir)\n",
    "\n",
    "            try:\n",
    "                stateDict = model.module.state_dict()\n",
    "            except AttributeError:\n",
    "                stateDict = model.state_dict()\n",
    "            torch.save(stateDict, f'{args.outputDir}/{args.taskName}.pt')\n",
    "            prevBestLoss = avgLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "together-seminar",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T20:54:31.182128Z",
     "start_time": "2021-03-23T20:54:30.599830Z"
    }
   },
   "outputs": [],
   "source": [
    "for epoch in trange(args.epochs):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elder-kentucky",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
